{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbedbd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e3e8c",
   "metadata": {},
   "source": [
    "## Task_1. Попробуйте видоизменить параметры разобранной на уроке нейронной сети таким образом, чтобы улучшить её точность. Проведите анализ:\n",
    "- Что приводит к ухудшению точности нейронной сети?\n",
    "- Что приводит к увеличению её точности?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1003a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "# преобразование массива в необходимый вид\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        l = layer2[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "# сигмоида и ее производная\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "# нормализация массива\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f0b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv(\"./Iris.csv\")\n",
    "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# формирование входных данных\n",
    "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = pd.DataFrame(iris_data, columns=columns)\n",
    "x = normalize(x.values)\n",
    "\n",
    "# формирование выходных данных(результатов)\n",
    "columns = ['Species']\n",
    "y = pd.DataFrame(iris_data, columns=columns)\n",
    "y = y.values\n",
    "y = y.flatten()\n",
    "y = to_one_hot(y)\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5437384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(neuron_number=2,learning_rate=10**-3,num_of_epochs=5):    \n",
    "    \n",
    "    errors = []\n",
    "    neuron_number = neuron_number\n",
    "    n = learning_rate\n",
    "    \n",
    "    #инициализация весов\n",
    "    w0 = 2*np.random.random((4, neuron_number)) - 1 # для входного слоя   - 4 входа, n выхода\n",
    "    w1 = 2*np.random.random((neuron_number, 3)) - 1 # для внутреннего слоя - n входов, 3 выхода\n",
    "\n",
    "    # процесс обучения\n",
    "    for _ in range(num_of_epochs):\n",
    "        for i in range(10000): \n",
    "\n",
    "            # прямое распространение(feed forward)\n",
    "            layer0 = X_train\n",
    "            layer1 = sigmoid(np.dot(layer0, w0))\n",
    "            layer2 = sigmoid(np.dot(layer1, w1))\n",
    "\n",
    "            # обратное распространение(back propagation) с использованием градиентного спуска\n",
    "            layer2_error = y_train - layer2\n",
    "            layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "\n",
    "            layer1_error = layer2_delta.dot(w1.T)\n",
    "            layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "\n",
    "            w1 += layer1.T.dot(layer2_delta) * n\n",
    "            w0 += layer0.T.dot(layer1_delta) * n\n",
    "\n",
    "            error = np.mean(np.abs(layer2_error))\n",
    "            errors.append(error)\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "    print(f'Model with {neuron_number} neurons, {n}-learning rate and {num_of_epochs} epochs has an accuracy of {round(accuracy,2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64ec17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_numbers = [1,2,3,4]\n",
    "learning_rate = [10**-3,10**-2,10**-1,10**0]\n",
    "num_of_epochs = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfd4c538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n",
      "Changing num. of neurons\n",
      "*************\n",
      "Model with 1 neurons, 0.001-learning rate and 5 epochs has an accuracy of 57.28.\n",
      "Model with 2 neurons, 0.001-learning rate and 5 epochs has an accuracy of 82.11.\n",
      "Model with 3 neurons, 0.001-learning rate and 5 epochs has an accuracy of 86.91.\n",
      "Model with 4 neurons, 0.001-learning rate and 5 epochs has an accuracy of 90.81.\n",
      "*************\n",
      "Changing learning rate\n",
      "*************\n",
      "Model with 1 neurons, 0.001-learning rate and 5 epochs has an accuracy of 57.34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivano\\AppData\\Local\\Temp\\ipykernel_5344\\3538275795.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 1 neurons, 0.01-learning rate and 5 epochs has an accuracy of 58.11.\n",
      "Model with 1 neurons, 0.1-learning rate and 5 epochs has an accuracy of 57.82.\n",
      "Model with 1 neurons, 1-learning rate and 5 epochs has an accuracy of 50.0.\n",
      "*************\n",
      "Changing num. of epochs\n",
      "*************\n",
      "Model with 1 neurons, 0.001-learning rate and 1 epochs has an accuracy of 56.56.\n",
      "Model with 1 neurons, 0.001-learning rate and 2 epochs has an accuracy of 57.41.\n",
      "Model with 1 neurons, 0.001-learning rate and 3 epochs has an accuracy of 57.48.\n",
      "Model with 1 neurons, 0.001-learning rate and 4 epochs has an accuracy of 55.86.\n"
     ]
    }
   ],
   "source": [
    "print('*************\\nChanging num. of neurons\\n*************')\n",
    "for i in range(4):\n",
    "    neural_net(neuron_numbers[i])\n",
    "    \n",
    "print('*************\\nChanging learning rate\\n*************')\n",
    "for i in range(4):\n",
    "    neural_net(neuron_numbers[0],learning_rate[i])\n",
    "\n",
    "print('*************\\nChanging num. of epochs\\n*************')\n",
    "for i in range(4):\n",
    "    neural_net(neuron_numbers[0],learning_rate[0],num_of_epochs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b2001",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a719fa",
   "metadata": {},
   "source": [
    "Видно, что на точность базовой NN влияют кол-во нейронов, learning rate и число эпох [не в учет кол-во слоёв]. Все эти показатели могут приводить к повышению точности предсказаний, хотя learning rate и число эпох могут ухудшить точность GD, если поставить слишком высокие значения"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
